{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8OiuOkdzV7T"
      },
      "source": [
        "# Entraînement aux Réseaux Antagonistes Génératifs \n",
        "## TRINCKLIN Paul\n",
        "## SEVESTRE Vincent"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dans ce notebook, un modèle de GAN est créé de toutes pièces. Il est mis à exécution pour générer des images de \"Pokemon\". Plus de 800 images sont utilisées pour entraîner le modèle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgMpZ-_2z8XG"
      },
      "source": [
        "## Traîtement des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rFmtCxz0mYZ"
      },
      "source": [
        "### Recadrage des images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "naI3Y1hbzQXo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "src = \"./processing_data/data_raw\" #imagesRGB brutes\n",
        "dst = \"./processing_data/resizedData\" # images RGB remises à la bonne taille\n",
        "\n",
        "os.mkdir(dst)\n",
        "\n",
        "for each in os.listdir(src):\n",
        "    img = cv2.imread(os.path.join(src,each))\n",
        "    img = cv2.resize(img,(256,256))\n",
        "    cv2.imwrite(os.path.join(dst,each), img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8s_ABie0pzA"
      },
      "source": [
        "### Transformation du code couleur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "2nvS9tdy0uEM"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "src = \"./processing_data/resizedData\"\n",
        "dst = \"./processing_data/resized_black/\"\n",
        "\n",
        "for each in os.listdir(src):\n",
        "    png = Image.open(os.path.join(src,each))\n",
        "    # print each\n",
        "    if png.mode == 'RGBA':\n",
        "        png.load() # required for png.split()\n",
        "        background = Image.new(\"RGB\", png.size, (0,0,0))\n",
        "        background.paste(png, mask=png.split()[3]) # 3 est le canal alpha\n",
        "        background.save(os.path.join(dst,each.split('.')[0] + '.jpg'), 'JPEG')\n",
        "    else:\n",
        "        png.convert('RGB')\n",
        "        png.save(os.path.join(dst,each.split('.')[0] + '.jpg'), 'JPEG')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Construction du GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import scipy.misc\n",
        "from utils import *\n",
        "import warnings\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Reshape\n",
        "from tensorflow.keras.layers import Flatten, BatchNormalization, Dense, Activation\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Générateur"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le générateur fonctione comme une sorte de réseau neuronal convolutif inverse. Un réseau neuronal convolutif typique, comme le réseau du discriminateur, transforme une matrice bidimensionnelle ou tridimensionnelle de valeurs de pixels en une probabilité unique. Un générateur, en revanche, prend un vecteur de bruit à d dimensions et le suréchantillonne pour en faire une image de 64 x 64 pixels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_generator():\n",
        "    \"\"\"\n",
        "    Crée le réseau du générateur\n",
        "    \"\"\"\n",
        "    generator = Sequential()\n",
        "    generator.add(Dense(units=4 * 4 * 512,\n",
        "                        kernel_initializer='glorot_uniform',\n",
        "                        input_shape=(1, 1, 100)))\n",
        "    generator.add(Reshape(target_shape=(4, 4, 512)))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=256, kernel_size=(5, 5),\n",
        "                                    strides=(2, 2), padding='same',\n",
        "                                    data_format='channels_last',\n",
        "                                    kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=128, kernel_size=(5, 5),\n",
        "                                    strides=(2, 2), padding='same',\n",
        "                                    data_format='channels_last',\n",
        "                                    kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=64, kernel_size=(5, 5),\n",
        "                                    strides=(2, 2), padding='same',\n",
        "                                    data_format='channels_last',\n",
        "                                    kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=3, kernel_size=(5, 5),\n",
        "                                    strides=(2, 2), padding='same',\n",
        "                                    data_format='channels_last',\n",
        "                                    kernel_initializer='glorot_uniform'))\n",
        "    generator.add(Activation('tanh'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=0.00015, beta_1=0.5)\n",
        "    generator.compile(loss='binary_crossentropy',\n",
        "                        optimizer=optimizer,\n",
        "                        metrics=None)\n",
        "\n",
        "    return generator"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Discriminateur"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le discriminateur est un réseau neuronal convolutif qui prend en entrée une image de taille 64 x 64 et renvoie un nombre scalaire unique décrivant si l'image d'entrée est \"réelle\" ou \"fausse\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_discriminator(image_shape):\n",
        "        \"\"\"\n",
        "        Crée le réseau du discriminateur\n",
        "        \"\"\"\n",
        "        discriminator = Sequential()\n",
        "        discriminator.add(Conv2D(filters=64, kernel_size=(5, 5),\n",
        "                                 strides=(2, 2), padding='same',\n",
        "                                 data_format='channels_last',\n",
        "                                 kernel_initializer='glorot_uniform',\n",
        "                                 input_shape=image_shape))\n",
        "        discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "        discriminator.add(Conv2D(filters=128, kernel_size=(5, 5),\n",
        "                                 strides=(2, 2), padding='same',\n",
        "                                 data_format='channels_last',\n",
        "                                 kernel_initializer='glorot_uniform'))\n",
        "        discriminator.add(BatchNormalization(momentum=0.5))\n",
        "        discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "        discriminator.add(Conv2D(filters=256, kernel_size=(5, 5),\n",
        "                                 strides=(2, 2), padding='same',\n",
        "                                 data_format='channels_last',\n",
        "                                 kernel_initializer='glorot_uniform'))\n",
        "        discriminator.add(BatchNormalization(momentum=0.5))\n",
        "        discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "        discriminator.add(Conv2D(filters=512, kernel_size=(5, 5),\n",
        "                                 strides=(2, 2), padding='same',\n",
        "                                 data_format='channels_last',\n",
        "                                 kernel_initializer='glorot_uniform'))\n",
        "        discriminator.add(BatchNormalization(momentum=0.5))\n",
        "        discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "        discriminator.add(Flatten())\n",
        "        discriminator.add(Dense(1))\n",
        "        discriminator.add(Activation('sigmoid'))\n",
        "\n",
        "        optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "        discriminator.compile(loss='binary_crossentropy',\n",
        "                              optimizer=optimizer,\n",
        "                              metrics=None)\n",
        "\n",
        "        return discriminator"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modèle complet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_adversarial(generator, discriminator):\n",
        "        \"\"\"\n",
        "        Construit le réseau complet\n",
        "        \"\"\"\n",
        "        gan = Sequential()\n",
        "        discriminator.trainable = False\n",
        "        gan.add(generator)\n",
        "        gan.add(discriminator)\n",
        "\n",
        "        optimizer = Adam(learning_rate=0.00015, beta_1=0.5)\n",
        "        gan.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
        "                    metrics=None)\n",
        "        return gan"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data loaders / savers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(dataset_path, image_shape, batch_size):\n",
        "    \"\"\"\n",
        "    Charge les données à partir de ce qui est présent dans \"dataset_path\"\n",
        "    \"\"\"\n",
        "    image_data_generator = ImageDataGenerator()\n",
        "    dataset_generator = image_data_generator.flow_from_directory(\n",
        "        dataset_path, target_size=(image_shape[0], image_shape[1]),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None)\n",
        "    return dataset_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_images(generated_images, epoch_no, batch_no):\n",
        "        \"\"\"\n",
        "        Affiche et sauvegarde les images\n",
        "        \"\"\"\n",
        "        print(\"Saving generated images to new_images/\")\n",
        "        plt.figure(figsize=(8, 8), num=2)\n",
        "        gs1 = gridspec.GridSpec(8, 8)\n",
        "        gs1.update(wspace=0, hspace=0)\n",
        "\n",
        "        for i in range(64):\n",
        "            ax1 = plt.subplot(gs1[i])\n",
        "            ax1.set_aspect('equal')\n",
        "            image = generated_images[i, :, :, :]\n",
        "            image += 1\n",
        "            image *= 127.5\n",
        "            fig = plt.imshow(image.astype(np.uint8))\n",
        "            plt.axis('off')\n",
        "            fig.axes.get_xaxis().set_visible(False)\n",
        "            fig.axes.get_yaxis().set_visible(False)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        save_name = 'new_images/generated_epoch' + str(\n",
        "            epoch_no + 1) + '_batch' + str(batch_no + 1) + '.png'\n",
        "        if not os.path.exists('new_images'):\n",
        "            os.mkdir('new_images')\n",
        "        plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
        "        plt.pause(0.0000000001)\n",
        "        plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Séquence d'entraînement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(dataset_path, image_shape, batch_size, epochs):\n",
        "    \"\"\"\n",
        "    Entraîne le GAN, et sauvegarde les images générées à chaque étape\n",
        "    \"\"\"\n",
        "    generator = get_generator()\n",
        "    discriminator = get_discriminator(image_shape)\n",
        "    gan = get_adversarial(generator, discriminator)\n",
        "\n",
        "    # Load dataset\n",
        "    dataset_generator = load_data(dataset_path, image_shape, batch_size)\n",
        "\n",
        "    number_of_batches = 150\n",
        "\n",
        "    # Ces variables vont conserver les pertes des deux modèles\n",
        "    adversarial_loss = np.empty(shape=1)\n",
        "    discriminator_loss = np.empty(shape=1)\n",
        "    batches = np.empty(shape=1)\n",
        "\n",
        "    # Pour pouvoir plot dans les boucles\n",
        "    plt.ion()\n",
        "\n",
        "    current_batch = 0\n",
        "\n",
        "    # Début de l'entraînement\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        print(\"Epoch \" + str(epoch + 1) + \"/\" + str(epochs) + \" :\")\n",
        "\n",
        "        for batch_number in range(number_of_batches):\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            real_images = dataset_generator.next()\n",
        "\n",
        "            # Normalisation des vecteurs images\n",
        "            real_images /= 127.5\n",
        "            real_images -= 1\n",
        "\n",
        "            # Étant donné que le dernier batch n'est pas de la même taille que les autres, \n",
        "            # il faut prendre en compte la taille\n",
        "            current_batch_size = real_images.shape[0]\n",
        "\n",
        "            # Création de bruit, de façon aléatoire\n",
        "            noise = np.random.normal(0, 1,\n",
        "                                        size=(current_batch_size,) + (1, 1, 100))\n",
        "\n",
        "            # Génération d'images par un simple passage dans le générateur\n",
        "            generated_images = generator.predict(noise)\n",
        "\n",
        "            # Ajout de bruit pour les labels qui seront donnés au discriminateur\n",
        "            real_y = (np.ones(current_batch_size) -\n",
        "                        np.random.random_sample(current_batch_size) * 0.2)\n",
        "            fake_y = np.random.random_sample(current_batch_size) * 0.2\n",
        "\n",
        "            # Entraînement du discriminateur\n",
        "            discriminator.trainable = True\n",
        "\n",
        "            d_loss = discriminator.train_on_batch(real_images, real_y)\n",
        "            d_loss += discriminator.train_on_batch(generated_images, fake_y)\n",
        "\n",
        "            discriminator_loss = np.append(discriminator_loss, d_loss)\n",
        "\n",
        "            # Puis entraînement du générateur\n",
        "            discriminator.trainable = False\n",
        "            print(\"Taille batch actuelle :\", current_batch_size)\n",
        "            noise = np.random.normal(0, 1,\n",
        "                                        size=(current_batch_size * 2,) +\n",
        "                                            (1, 1, 100))\n",
        "\n",
        "            # On reprend la formule précédente de bruit, en inversant les labels pour tromper le discriminateur\n",
        "            # ici la formule correspond à celle de \"real_y\" plus haut\n",
        "            fake_y = (np.ones(current_batch_size * 2) -\n",
        "                        np.random.random_sample(current_batch_size * 2) * 0.2)\n",
        "\n",
        "            g_loss = gan.train_on_batch(noise, fake_y)\n",
        "            adversarial_loss = np.append(adversarial_loss, g_loss)\n",
        "            batches = np.append(batches, current_batch)\n",
        "\n",
        "            # Sauvegarde d'image tous les 50 batchs\n",
        "            if ((batch_number + 1) % 50 == 0 and\n",
        "                    current_batch_size == batch_size):\n",
        "                save_images(generated_images, epoch, batch_number)\n",
        "\n",
        "            time_elapsed = time.time() - start_time\n",
        "\n",
        "            # Affichage des valeurs de pertes\n",
        "            print(\"     Batch \" + str(batch_number + 1) + \"/\" +\n",
        "                    str(number_of_batches) +\n",
        "                    \" Perte générateur | Perte discriminateur : \" +\n",
        "                    str(g_loss) + \" | \" + str(d_loss) + ' - Temps batch ' +\n",
        "                    str(time_elapsed) + ' s.')\n",
        "\n",
        "            current_batch += 1\n",
        "\n",
        "        # Sauvegarde des poids du modèle tous les 5 epochs\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            discriminator.trainable = True\n",
        "            if not os.path.exists('models'):\n",
        "                os.mkdir('models')\n",
        "            generator.save('models/generator_epoch' + str(epoch) + '.hdf5')\n",
        "            discriminator.save('models/discriminator_epoch' +\n",
        "                                str(epoch) + '.hdf5')\n",
        "\n",
        "        # A chaque époch, on traçe les courbes de pertes\n",
        "        plt.figure(1)\n",
        "        plt.plot(batches, adversarial_loss, color='green',\n",
        "                    label='Perte Générateur')\n",
        "        plt.plot(batches, discriminator_loss, color='blue',\n",
        "                    label='Perte Discriminateur')\n",
        "        plt.title(\"Entraînement GAN\")\n",
        "        plt.xlabel(\"Itération Batch\")\n",
        "        plt.ylabel(\"Perte\")\n",
        "        plt.legend()\n",
        "        plt.pause(0.0000000001)\n",
        "        plt.show()\n",
        "        plt.savefig('trainingLossPlot.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_path = './data/'\n",
        "batch_size = 64\n",
        "image_shape = (64, 64, 3)\n",
        "epochs = 45\n",
        "train_model(dataset_path, image_shape, batch_size, epochs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Traitement des résultats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Building file denoising_6.gif with imageio.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        }
      ],
      "source": [
        "# Clip gif du débruitage \n",
        "import moviepy.editor as mpy\n",
        "clip = mpy.ImageSequenceClip(sequence=\"new_images/\", fps=6)\n",
        "clip.write_gif('denoising_6.gif')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"denoising_10.gif\" width=\"450\" align=\"center\">"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "67bfac4f4aefe1c16f1836a62d55b6e6baa7aba1ac5ce70e93ee8e90eb4f073a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
